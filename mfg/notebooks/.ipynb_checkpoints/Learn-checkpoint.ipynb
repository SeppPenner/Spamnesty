{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn import preprocessing\n",
    "from main.models import Conversation, Message, SpamCategory\n",
    "\n",
    "def clean_up(text):\n",
    "    # remove html tags or pseudo-html tags\n",
    "    cleaned = re.sub(r'(<[a-z]+.*?>)|(\\[http:.*?\\])|(</.*?>)|([^ \\n]{50,})', '{}', text)\n",
    "    return cleaned\n",
    "\n",
    "def get_classified_data():\n",
    "    msgs = []\n",
    "    categories = []\n",
    "    conversations = Conversation.objects.filter(classified=True)\n",
    "    for conversation in conversations:\n",
    "        conversation_msgs = conversation.messages\n",
    "        if len(conversation_msgs) > 0:\n",
    "            msg = conversation.messages[0]\n",
    "            msgs.append(clean_up(msg.subject + ' ' + msg.body))\n",
    "            # NOTE: The targets should be integers\n",
    "            # TODO: FIX THIS to make integers and create mapping dict\n",
    "            categories.append(conversation.category_id)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    target = le.fit_transform(categories)\n",
    "    result = {'data': msgs, 'target': target, 'labels': categories, 'classes': le.classes_,\n",
    "              'class_names': list(map((lambda c: SpamCategory.objects.filter(id=c)[0].name), data['classes']))}\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = get_classified_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages: 197, Classes: 7\n"
     ]
    }
   ],
   "source": [
    "# msgs are the untokenized messages, labels are the categories for the messages\n",
    "print(\"Messages: {}, Classes: {}\".format(len(data['data']), len(data['classes'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Better way to split training/testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(data['data'], data['target'], train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", min_df=2,\n",
    "                            token_pattern='(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b')\n",
    "\n",
    "# Learn the vocabulary\n",
    "vectorizer.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1629"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<157x1629 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8311 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "train_dtm = vectorizer.transform(x_train)\n",
    "train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of the document-term matrix\n",
    "type(train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# transform testing data\n",
    "test_dtm = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 1629)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 1629)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 2.93 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time nb.fit(train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72499999999999998"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  1,  0,  0,  0],\n",
       "       [ 2,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1,  3,  0,  7,  0],\n",
       "       [ 0,  0,  0,  0,  2,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 18,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  3]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_pred_prob = nb.predict_proba(test_dtm)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 4, 3, 5, 5, 5, 3, 5, 5, 3, 3, 5, 3, 3, 1, 3, 3, 5, 5, 5, 3, 5,\n",
       "       2, 0, 6, 5, 3, 5, 5, 5, 2, 4, 6, 2, 5, 5, 6, 3, 1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part 7. Examining a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1629"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vectorizer.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandoned', 'abidjan', 'able', 'abroad', 'absolutely', 'abuja', 'abuse', 'accept', 'acceptable', 'access', 'accomplish', 'according', 'accordingly', 'account', 'accountant', 'accounts', 'accurate', 'acquaintance', 'act', 'action', 'active', 'activities', 'activity', 'actual', 'ad', 'add', 'added', 'addition', 'address', 'addressed', 'addressee', 'addresses', 'advance', 'advantage', 'adventurous', 'advertisement', 'advertisements', 'advice', 'advise', 'advised', 'affordable', 'afraid', 'africa', 'african', 'age', 'agencies', 'agency', 'agent', 'ago', 'agreed']\n"
     ]
    }
   ],
   "source": [
    "# examine the first 50 tokens\n",
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['website', 'websites', 'week', 'weekly', 'weeks', 'weight', 'west', 'western', 'whatsapp', 'wicked', 'widow', 'widows', 'wife', 'williams', 'willing', 'willingness', 'winner', 'winning', 'wire', 'wish', 'wishes', 'withdraw', 'woman', 'women', 'won', 'wordpress', 'words', 'work', 'worked', 'working', 'works', 'world', 'worldwide', 'worry', 'worth', 'write', 'writing', 'wrong', 'wrote', 'www', 'xia', 'yahoo', 'yandex', 'year', 'years', 'yes', 'york', 'youtube', 'zip', 'zone']\n"
     ]
    }
   ],
   "source": [
    "# examine the last 50 tokens\n",
    "print(X_train_tokens[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  2.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 2.,  3.,  5., ...,  1.,  2.,  1.],\n",
       "       [ 0.,  0.,  2., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1629)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Most informative features\n",
    "import numpy as np\n",
    "def print_top10(vectorizer, clf, class_labels):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "        print(\"%s: %s\" % (class_label,\n",
    "              \" \".join(feature_names[j] for j in top10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website: regards interested email computer services com web website design development\n",
      "Medical: click offers weeks designed life blood health free weight low\n",
      "Sales: registration apps app time com email information free mail mobile\n",
      "Click bait: download simple report insurance http free account unsubscribe domain click\n",
      "Business: investment money work account resources com business company capital email\n",
      "Money scam: account payment address funds transfer email fund contact money bank\n",
      "Dating: nice women like meet don man married looking hope want\n"
     ]
    }
   ],
   "source": [
    "print_top10(vectorizer, nb, data['class_names'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
